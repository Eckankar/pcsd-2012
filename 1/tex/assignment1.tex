\documentclass[11pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

\title{Principles of Computer System Design\\Assignment 1}
\author{Jacob Wejendorp\\Sebastian Paaske Tørholm\\Kasper Fabæch Brandt}

\begin{document}
\maketitle
\section{Exercises}
\subsection{Question 1, Fundamental abstractions}
\subsubsection{Model for implementing shared address space}
One could model an address in the shared address space as a 2-tuple of two
elements; the address or identifier of a machine, and the address on the given
machine. This is highly scalable, as each component is separated and each of
the two addresses can be interpreted independently. With suitable encoding,
no limitation is needed on the size of either the machine address or memory
address.

This model requires a naming service to determine what address each machine
has. This address could, for instance, be an IP address.

\subsubsection{Pseudocode for implementation of READ/WRITE}

\begin{verbatim}
def READ((machineaddr, dataaddr)):
    machine = connect(machineaddr)
    data = machine.read(dataaddr)
    machine.disconnect()

    return data
\end{verbatim}

\begin{verbatim}
def WRITE((machineaddr, dataaddr), data):
    machine = connect(machineaddr)
    machine.write(dataaddr, data)
    machine.disconnect()
\end{verbatim}

Here, \texttt{connect} is a function that produces a connection object to
communicate with the given machine, and said object has a \texttt{read} and
\texttt{write} method that works locally on that machine.
Pattern matching is used to extract the parts of the address from the full
address (tuple).

\subsubsection{Are READ/WRITE against memory atomic?}
% TODO

\subsection{Question 2, Hardware trends}

\begin{tabular}{|r|c|c|c|}
    \hline
                    & HDD & SSD & RAM\\\hline
    Access time     & 10.000 us & ~100us & 0.1 us\\\hline % Source: slides from lecture 3, and http://en.wikipedia.org/wiki/Solid-state_drive
    Capacity (GB)   & 1000-2000 & 128-256 & 1-4 \\\hline
    Cost (kr/GB)    & 0.35 & 4.5-5.5 & 32 \\\hline
    Reliability     & & & \\\hline % Still dont know..
    Power consumption & <8w & 0.15W & ~1.65W \\\hline 
	% Datasheets: Samsung Spinpoint F1 1TB disk, Samsung 830 SSD and Samsung DDR3 ram
	% http://www.samsung.com/us/business/semiconductor/news/downloads/dsF11008.pdf
	% http://www.samsung.com/us/business/oem-solutions/pdfs/PM830_mSATA%20SSD_32_64_128_256GB_Spec_1.0.pdf
	% http://www.samsung.com/global/business/semiconductor/file/2011/product/2011/6/24/013928ds_k4b1g1646g_x16only_rev111.pdf

\end{tabular}
Capacity and cost pr capacity data retrieved from EDBpriser.dk, Nov 29 2012.
Ram - 1 block at a time, no sets.

Reliability - read errors? Mean time to failure?


\subsection{Question 3, Performance}
\subsubsection{How does concurrency influence latency?}

The latency will be lower, if the overhead of scheduling, work partitioning and
other concurrency related overhead is less than the gain from parallelizing the
computation and vice versa. This will in practice favor larger computations and
datasets, while influencing smaller jobs negatively.

\subsubsection{What is the difference between dallying and batching?}

Batching is the act of performing several related actions simultaneously.
Dallying is the act of postponing an action, in order to later potentially batch
the action together with another related action, or maybe avoid doing it at all.

As an example, we can look at memory mapped files, where data is read from the
disk in batches (pages).
Write requests are dallied by only writing changes to ram, postponing disk
writes until strictly necessary, potentially batching several changes to a page
into one disk write.

\subsubsection{Is caching an example of fast path optimization?}

Caching exploits the fact that more frequently accessed items are more likely
to be in the cache. By this virtue, caching will often improve the common case
and is therefore an example of fast path optimization.

\subsection{Question 4, Experimental design}
\subsubsection{How to test bandwidth in case of only cache hits}
\begin{itemize}
    \item Allocate a small piece of memory. (For instance the size of a page)
    \item Initialize the memory to all 0s. It should now be cached.
    \item Start timing.
    \item Iterate through each byte in the memory n times, incrementing each byte
          and saving it back. This should all hit cache.
    \item Stop timing.
\end{itemize}

Simple math can now be performed based on the size of the block of memory and
the time taken, in order to figure out the bandwidth achieved.

\subsubsection{How to test bandwidth in case of only cache misses}
\begin{itemize}
    \item Allocate a large piece of memory, at least twice the size of the cache.
    \item Initialize the memory to all 0s. A reasonable cache would now have the last part of the memory allocated cached. 
    \item Start timing.
    \item Iterate through the memory n times, accessing only the first byte
          of each page. Since memory is cached in pages, each access should be
          unaffected by the one before it. The size of the allocated memory should
          ensure that by the time a page is accessed, it isn't cached.
    \item Stop timing.
\end{itemize}

The same math can be performed as in the first experiment to determine the
bandwidth achieved.

\end{document}

